{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: Comenzando\n",
    "## Importación de bibliotecas y configuración de entorno: \n",
    "Se importan las bibliotecas necesarias, como TensorFlow, sklearn y numpy. Además, se establece la semilla para la reproducibilidad de los resultados y se configura la variable de entorno 'PATH' para el entorno de Vivado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 05:03:57.186222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-23 05:03:57.296922: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención y preparación de datos: \n",
    "Este código carga imágenes de entrenamiento y prueba desde carpetas específicas, las redimensiona a un tamaño deseado y las almacena junto con sus etiquetas en matrices numpy para su posterior procesamiento. Los datos se dividen en imagenes (X) y etiquetas (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow y tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Librerias de ayuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.24.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "Dimensiones de las imágenes: (40, 60, 60)\n",
      "Dimensiones de las etiquetas: (40,)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Tamaño deseado para todas las imágenes\n",
    "nuevo_ancho = 60\n",
    "nuevo_alto = 60\n",
    "\n",
    "# Ruta a la carpeta de imágenes\n",
    "data_dir = \"./signals\"\n",
    "\n",
    "# Función para cargar imágenes y etiquetas de una sola carpeta\n",
    "def load_images_and_labels(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder_name in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for image_file in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, image_file)\n",
    "                # Leer la imagen en escala de grises\n",
    "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                # Redimensionar la imagen\n",
    "                image = cv2.resize(image, (nuevo_ancho, nuevo_alto))\n",
    "                # Normalizar la imagen\n",
    "                image = image / 255.0\n",
    "                images.append(image)\n",
    "                # Usar el nombre de la carpeta como etiqueta\n",
    "                labels.append(folder_name)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Cargar imágenes y etiquetas de la carpeta de datos\n",
    "images, labels = load_images_and_labels(data_dir)\n",
    "\n",
    "# Crear un diccionario con los datos\n",
    "data = {'data': images, 'target': labels}\n",
    "\n",
    "# Organizar los datos según la estructura deseada\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Verificar las dimensiones de los datos cargados\n",
    "print(\"Dimensiones de las imágenes:\", X.shape)\n",
    "print(\"Dimensiones de las etiquetas:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimir información sobre el conjunto de datos: \n",
    "Imprime la forma (shape) del conjunto de datos `X` y las etiquetas `y` utilizando `X.shape` y `y.shape`. Además, imprime las primeras cinco filas de características y etiquetas utilizando `X[:5]` y `y[:5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 60, 60) (40,)\n",
      "[[[0.79215686 0.8627451  0.89411765 ... 0.10588235 0.2745098  0.85098039]\n",
      "  [0.6745098  0.81176471 0.89019608 ... 0.11764706 0.26666667 0.83137255]\n",
      "  [0.60784314 0.7372549  0.8745098  ... 0.10980392 0.34901961 0.81960784]\n",
      "  ...\n",
      "  [0.4        0.40784314 0.38039216 ... 0.54117647 0.66666667 0.67058824]\n",
      "  [0.52156863 0.36862745 0.37254902 ... 0.53333333 0.68235294 0.67843137]\n",
      "  [0.54901961 0.65098039 0.55294118 ... 0.52156863 0.68235294 0.69019608]]\n",
      "\n",
      " [[0.22745098 0.19607843 0.14901961 ... 0.8627451  0.39215686 0.8627451 ]\n",
      "  [0.25490196 0.24313725 0.24705882 ... 0.64705882 0.49803922 0.60784314]\n",
      "  [0.32156863 0.25882353 0.20392157 ... 0.33333333 0.45490196 0.76862745]\n",
      "  ...\n",
      "  [0.10196078 0.05098039 0.37647059 ... 0.4745098  0.35686275 0.55686275]\n",
      "  [0.23921569 0.11372549 0.43529412 ... 0.62352941 0.77647059 0.81568627]\n",
      "  [0.18823529 0.15686275 0.49411765 ... 0.6745098  0.83921569 0.88235294]]\n",
      "\n",
      " [[0.31764706 0.30980392 0.28235294 ... 0.34509804 0.29411765 0.49803922]\n",
      "  [0.36470588 0.31764706 0.31764706 ... 0.35294118 0.34509804 0.43921569]\n",
      "  [0.36470588 0.35686275 0.36862745 ... 0.38823529 0.38039216 0.39607843]\n",
      "  ...\n",
      "  [0.2627451  0.23137255 0.24705882 ... 0.26666667 0.43529412 0.46666667]\n",
      "  [0.39607843 0.41176471 0.38823529 ... 0.54509804 0.5372549  0.36470588]\n",
      "  [0.48235294 0.46666667 0.42352941 ... 0.41568627 0.28627451 0.13333333]]\n",
      "\n",
      " [[0.12156863 0.12156863 0.12941176 ... 0.27058824 0.30588235 0.25098039]\n",
      "  [0.10980392 0.11372549 0.11764706 ... 0.24313725 0.25882353 0.28235294]\n",
      "  [0.09803922 0.10196078 0.10980392 ... 0.25882353 0.24705882 0.20392157]\n",
      "  ...\n",
      "  [0.02745098 0.03921569 0.0745098  ... 0.03137255 0.02352941 0.01568627]\n",
      "  [0.04313725 0.02745098 0.07843137 ... 0.02745098 0.02745098 0.03137255]\n",
      "  [0.05490196 0.0745098  0.08235294 ... 0.05882353 0.04705882 0.03137255]]\n",
      "\n",
      " [[0.12941176 0.1254902  0.12156863 ... 0.03921569 0.05490196 0.08235294]\n",
      "  [0.59607843 0.59215686 0.61568627 ... 0.27058824 0.30196078 0.2745098 ]\n",
      "  [0.6        0.59607843 0.61176471 ... 0.37254902 0.31372549 0.23529412]\n",
      "  ...\n",
      "  [0.4        0.40392157 0.38431373 ... 0.30196078 0.24313725 0.1254902 ]\n",
      "  [0.4        0.40392157 0.38823529 ... 0.33333333 0.25098039 0.1254902 ]\n",
      "  [0.05098039 0.05490196 0.08235294 ... 0.10588235 0.05098039 0.05098039]]]\n",
      "['no_estacionarse' 'no_estacionarse' 'no_estacionarse' 'no_estacionarse'\n",
      " 'no_estacionarse' 'no_estacionarse' 'no_estacionarse' 'no_estacionarse'\n",
      " 'no_estacionarse' 'no_estacionarse' 'no_estacionarse' 'no_estacionarse'\n",
      " 'no_estacionarse' 'no_estacionarse' 'no_estacionarse' 'no_estacionarse'\n",
      " 'no_estacionarse' 'no_estacionarse' 'no_estacionarse' 'no_estacionarse'\n",
      " 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso'\n",
      " 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso'\n",
      " 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso'\n",
      " 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso'\n",
      " 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso' 'ceda_el_paso']\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(X[:5])\n",
    "print(y[:40])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque de código, se realiza la codificación de las etiquetas `y` para el entrenamiento del modelo. Primero, se utiliza `LabelEncoder()` para transformar las etiquetas de clase de cadena a numérico. Luego, se aplica `to_categorical` para convertir estas etiquetas numéricas en un formato binario \"One Hot\" para la clasificación multiclase. Después, se divide el conjunto de datos en conjuntos de entrenamiento y prueba utilizando `train_test_split`, con un tamaño de prueba del 20% y una semilla aleatoria de 42 para la reproducibilidad de los resultados.\n",
    "\n",
    "Además, se realiza el escalado de las características del conjunto de datos utilizando `StandardScaler()` para asegurar que todas las características tengan una media de cero y una desviación estándar de uno, lo que puede mejorar el rendimiento del modelo. \n",
    "\n",
    "### Archivos creados:\n",
    "Se guardan los conjuntos de datos de entrenamiento y prueba, así como las etiquetas, en archivos `.npy`, junto con la clase original de las etiquetas.\n",
    "* x_train_val.npy\n",
    "* x_test.npy\n",
    "* y_train_val.npy\n",
    "* y_test.npy\n",
    "* classes.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y, 5)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Aplanar cada imagen\n",
    "X_train_val_flat = X_train_val.reshape(X_train_val.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Escalar cada dimensión por separado\n",
    "scaler = StandardScaler()\n",
    "X_train_val_scaled = scaler.fit_transform(X_train_val_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "\n",
    "# Remodelar los datos escalados a su forma original\n",
    "X_train_val_scaled = X_train_val_scaled.reshape(X_train_val.shape)\n",
    "X_test_scaled = X_test_scaled.reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_val.npy', X_train_val)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train_val.npy', y_train_val)\n",
    "np.save('y_test.npy', y_test)\n",
    "np.save('classes.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de modelo\n",
    "Se construye un modelo de red neuronal con tres capas ocultas, cada una con activación ReLU, seguidas de una capa de salida con activación softmax. Las capas ocultas tienen 64, 32 y 32 neuronas respectivamente, mientras que la capa de salida tiene 5 neuronas para clasificar en cinco clases diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo\n",
    "Utilizaremos el optimizador Adam con una pérdida de entropía cruzada categórica. Los callbacks disminuirán la tasa de aprendizaje y guardarán el modelo en un directorio llamado 'model_1'. El modelo no es muy complejo, así que esto debería tomar solo unos minutos incluso en la CPU. Si has reiniciado el kernel del notebook después de entrenar una vez, establece `train = False` para cargar el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(60, 60)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(\n",
    "        stop_patience=1000,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=10,\n",
    "        lr_epsilon=0.000001,\n",
    "        lr_cooldown=2,\n",
    "        lr_minimum=0.0000001,\n",
    "        outputDir='model_1',\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        batch_size=1024,\n",
    "        epochs=30,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks.callbacks,\n",
    "    )\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    model = load_model('model_1/KERAS_check_best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion del rendimiento\n",
    "Esta sección evalúa el rendimiento del modelo mediante la verificación de la precisión y la creación de una curva ROC.\n",
    "Se utiliza la función accuracy_score de scikit-learn para calcular la precisión del modelo. Luego, se genera una curva ROC utilizando la función makeRoc del módulo de visualización, lo que proporciona una representación gráfica del rendimiento del modelo en diferentes umbrales de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predicciones\n",
    "y_keras = model.predict(X_test)\n",
    "\n",
    "# Calcula la precisión\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "# Genera la curva ROC\n",
    "plt.figure(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_ker, le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir el modelo en firmware FPGA con hls4ml\n",
    "Ahora pasaremos por los pasos para convertir el modelo que entrenamos en un firmware FPGA optimizado de baja latencia con hls4ml. Primero, evaluaremos su rendimiento de clasificación para asegurarnos de que no hayamos perdido precisión utilizando tipos de datos de punto fijo. Luego, sintetizaremos el modelo con Vivado HLS y verificaremos las métricas de latencia y uso de recursos de la FPGA.\n",
    "\n",
    "### Crear una configuración y un modelo de hls4ml\n",
    "La biblioteca de inferencia de redes neuronales hls4ml se controla a través de un diccionario de configuración. En este ejemplo, utilizaremos la variación más simple; en ejercicios posteriores se verán configuraciones más avanzadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "\n",
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, output_dir='model_1/hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiza la arquitectura del modelo generado por hls4ml, muestra las formas de las capas y los tipos de datos.La visualización se genera utilizando la función plot_model de hls4ml.utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar, predecir\n",
    "Ahora necesitamos asegurarnos de que el rendimiento de este modelo siga siendo bueno. Compilamos el hls_model, y luego usamos hls_model.predict para ejecutar el firmware de la FPGA con emulación bit-precisa en la CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación:\n",
    "Después de comparar, calculamos la precisión de ambos modelos utilizando la función `accuracy_score` de scikit-learn. Luego, creamos un nuevo gráfico para comparar las curvas ROC de ambos modelos utilizando la función `makeRoc` del módulo `plotting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_keras, le.classes_)\n",
    "plt.gca().set_prop_cycle(None)  # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_hls, le.classes_, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "lines = [Line2D([0], [0], ls='-'), Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "\n",
    "leg = Legend(ax, lines, labels=['keras', 'hls4ml'], loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sintesis\n",
    "Ahora vamos a utilizar Vivado HLS para sintetizar el modelo. Podemos ejecutar la construcción utilizando un método de nuestro objeto hls_model. Después de ejecutar este paso, podemos integrar el IP generado en un flujo de trabajo para compilarlo para una placa FPGA específica. En este caso, simplemente revisaremos los informes que genera Vivado HLS, verificando la latencia y el uso de recursos.\n",
    "\n",
    "**Esto puede llevar varios minutos.**\n",
    "\n",
    "Mientras la Síntesis en C se está ejecutando, podemos monitorear el progreso observando el archivo de registro, abriendo una terminal desde el directorio de inicio del cuaderno y ejecutando:\n",
    "\n",
    "`tail -f model_1/hls4ml_prj/vivado_hls.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar los informes\n",
    "Imprime los informes generados por Vivado HLS. Presta atención a las secciones de Latencia y 'Estimaciones de utilización'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('model_1/hls4ml_prj/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "Dado que `ReuseFactor = 1`, esperamos que cada multiplicación utilizada en la inferencia de nuestra red neuronal use 1 DSP. ¿Es esto lo que observamos? (Ten en cuenta que la capa Softmax debería usar 5 DSP, o 1 por clase).\n",
    "Calcula cuántas multiplicaciones se realizan para la inferencia de esta red...\n",
    "(Discutiremos el resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
