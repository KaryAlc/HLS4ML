{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209d2b58",
   "metadata": {},
   "source": [
    "# Parte 5: Árboles de Decisión Potenciados\n",
    "\n",
    "El paquete conifer se creó a partir de hls4ml, proporcionando un conjunto similar de características pero específicamente dirigido a la inferencia de Árboles de Decisión Potenciados. En este cuaderno entrenaremos un GradientBoostingClassifier con scikit-learn, utilizando el mismo conjunto de datos de etiquetado de jets que en los otros cuadernos de tutoriales. Luego convertiremos el modelo usando conifer y ejecutaremos la predicción y síntesis de precisión de bits como lo hicimos con hls4ml anteriormente.\n",
    "\n",
    "`conifer` esta disponible en GitHub [aqui](https://github.com/thesps/conifer), y tenemos una publicación que describe la implementación y el rendimiento de la inferencia en detalle [aqui](https://iopscience.iop.org/article/10.1088/1748-0221/15/05/P05026/pdf).\n",
    "\n",
    "<img src=\"https://github.com/thesps/conifer/blob/master/conifer_v1.png?raw=true\" width=\"250\" alt=\"conifer\">\n",
    "\n",
    "En este código, estamos importando las bibliotecas necesarias para trabajar con modelos de árboles de decisión mejorados mediante el paquete conifer. Utilizamos NumPy para operaciones numéricas, scikit-learn para entrenar el modelo de clasificación, joblib para guardar y cargar modelos entrenados, conifer para la conversión del modelo y plotting y matplotlib.pyplot para visualización. También configuramos la variable de entorno PATH para incluir la ruta de Vivado HLS y establecemos la semilla aleatoria np.random.seed(0) para garantizar la reproducibilidad de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import conifer\n",
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18354699",
   "metadata": {},
   "source": [
    "## Cargar dataset\n",
    "Este código carga el conjunto de datos previamente descargado y guardado en archivos numpy. Los archivos contienen los conjuntos de datos de entrenamiento y prueba (características y etiquetas) junto con las clases.\n",
    "\n",
    "- `X_train_val`: contiene las características del conjunto de datos de entrenamiento y validación.\n",
    "- `X_test`: contiene las características del conjunto de datos de prueba.\n",
    "- `y_train_val`: contiene las etiquetas del conjunto de datos de entrenamiento y validación.\n",
    "- `y_test`: contiene las etiquetas del conjunto de datos de prueba.\n",
    "- `classes`: contiene las clases del conjunto de datos.\n",
    "\n",
    "Los argumentos `allow_pickle=True` son necesarios porque los archivos numpy contienen objetos Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = np.load('X_train_val.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train_val = np.load('y_train_val.npy')\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "classes = np.load('classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24658fb4",
   "metadata": {},
   "source": [
    "Necesitamos transformar las etiquetas de prueba desde los valores codificados en one-hot a etiquetas simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f304bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(classes)\n",
    "ohe = OneHotEncoder().fit(le.transform(classes).reshape(-1, 1))\n",
    "y_train_val = ohe.inverse_transform(y_train_val.astype(int))\n",
    "y_test = ohe.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305e22c",
   "metadata": {},
   "source": [
    "## Entrenar un `GradientBoostingClassifier`\n",
    "Usando con 20 estimadores y una profundidad máxima de 3. El número de árboles de decisión será n_estimators * n_classes, por lo que será de 100 para este conjunto de datos. Si estás volviendo a este cuaderno después de haber entrenado el BDT una vez, establece train = False para cargar el modelo en lugar de volver a entrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5044231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "if train:\n",
    "    clf = GradientBoostingClassifier(n_estimators=20, learning_rate=1.0, max_depth=3, random_state=0, verbose=1).fit(\n",
    "        X_train_val, y_train_val.ravel()\n",
    "    )\n",
    "    if not os.path.exists('model_5'):\n",
    "        os.makedirs('model_5')\n",
    "    joblib.dump(clf, 'model_5/bdt.joblib')\n",
    "else:\n",
    "    clf = joblib.load('model_5/bdt.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9857c2",
   "metadata": {},
   "source": [
    "## Crea una configuración de conifer\n",
    "\n",
    "Similarmente a hls4ml, podemos usar un método de utilidad para obtener una plantilla del diccionario de configuración que podemos modificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = conifer.backends.xilinxhls.auto_config()\n",
    "cfg['OutputDir'] = 'model_5/conifer_prj'\n",
    "cfg['XilinxPart'] = 'xcu250-figd2104-2L-e'\n",
    "plotting.print_dict(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ca740",
   "metadata": {},
   "source": [
    "## Convert the model\n",
    "La sintaxis para la conversión del modelo con conifer es un poco diferente a la de hls4ml. Construimos un objeto conifer.model, proporcionando el BDT entrenado, el convertidor correspondiente a la biblioteca que utilizamos, el \"backend\" de conifer al que deseamos apuntar y la configuración.\n",
    "\n",
    "conifer tiene convertidores para:\n",
    "\n",
    "- sklearn\n",
    "- xgboost\n",
    "- tmva\n",
    "\n",
    "Y backends:\n",
    "\n",
    "- vivadohls\n",
    "- vitishls\n",
    "- xilinxhls (usa cualquiera de vivado o vitis que esté en la ruta)\n",
    "- vhdl\n",
    "\n",
    "Aquí usaremos el convertidor de sklearn, ya que así es como entrenamos nuestro modelo, y el backend vivadohls. Para BDT más grandes con muchos más árboles o profundidad, puede ser preferible generar VHDL directamente usando el backend vhdl para obtener el mejor rendimiento. Consulta nuestro artículo para ver la comparación de rendimiento entre esos backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = conifer.model(clf, conifer.converters.sklearn, conifer.backends.vivadohls, cfg)\n",
    "cnf.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e487b",
   "metadata": {},
   "source": [
    "## perfil\n",
    "Del mismo modo que en hls4ml, podemos visualizar la distribución de los parámetros del BDT para orientar la elección de la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993fef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c840ca4",
   "metadata": {},
   "source": [
    "## Ejecutar inferencia\n",
    "Ahora podemos realizar la inferencia del BDT con sklearn, y también la simulación exacta de bits utilizando Vivado HLS. La salida que produce el BDT de conifer es equivalente al método decision_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_skl = clf.decision_function(X_test)\n",
    "y_cnf = cnf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486535e",
   "metadata": {},
   "source": [
    "## Checar el rendimiento\n",
    "Imprime la precisión de las evaluaciones de sklearn y conifer, y traza las curvas ROC. Deberíamos ver que podemos llegar bastante cerca de la precisión de las redes neuronales de las partes 1-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a87c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = ohe.transform(y_test).toarray().astype(int)\n",
    "print(\"Accuracy sklearn: {}\".format(accuracy_score(np.argmax(yt, axis=1), np.argmax(y_skl, axis=1))))\n",
    "print(\"Accuracy conifer: {}\".format(accuracy_score(np.argmax(yt, axis=1), np.argmax(y_cnf, axis=1))))\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(yt, y_skl, classes)\n",
    "plt.gca().set_prop_cycle(None)  # reset the colors\n",
    "_ = plotting.makeRoc(yt, y_cnf, classes, linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c43d82",
   "metadata": {},
   "source": [
    "## Sintetizar\n",
    "Ahora ejecuta el paso de Síntesis en C de Vivado HLS para producir una IP que podamos usar, e inspecciona los recursos estimados y la latencia. Puedes ver alguna salida en vivo mientras se ejecuta la síntesis abriendo un terminal desde la página de inicio de Jupyter y ejecutando:\n",
    "`tail -f model_5/conifer_prj/vivado_hls.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721814ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1efe07",
   "metadata": {},
   "source": [
    "## Leer informe\n",
    "Podemos utilizar una utilidad de hls4ml para leer el informe de Vivado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "hls4ml.report.read_vivado_report('model_5/conifer_prj/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
